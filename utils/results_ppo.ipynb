{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from torch.distributions import Multinomial, Bernoulli\n",
    "from tensorboard_logger import configure, log_value\n",
    "from utils import utils\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_b_16 = torchvision.models.vit_b_16(weights='ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1')\n",
    "agent = utils.get_model()\n",
    "checkpoint = torch.load(\"/media/samar/HDD1T/rl/PatchDrop-main/cv_dir/pretrain_ppo/ckpt_E_0_A_0.680_R_4.88E-01\")\n",
    "agent.load_state_dict(checkpoint['agent'])\n",
    "agent.eval().cuda()\n",
    "vit_b_16.eval().cuda();\n",
    "mappings, _, patch_size = utils.action_space_model()\n",
    "lr_size = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32,scale=True),\n",
    "    v2.Resize(size=384,interpolation=torchvision.transforms.InterpolationMode.BICUBIC),\n",
    "    v2.CenterCrop(384),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valdata = torchvision.datasets.ImageFolder(root=\"/media/samar/HDD1T/rl/PatchDrop-main/50-dataset/val\",transform=val_transform)\n",
    "valloader = DataLoader(valdata,batch_size=16,num_workers = 8,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [38:12<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3340, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "average_patch_use = 0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in tqdm.tqdm(enumerate(valloader), total=len(valloader)):\n",
    "\n",
    "        inputs, targets = Variable(inputs), Variable(targets).cuda(non_blocking=True)\n",
    "        \n",
    "        inputs = inputs.cuda()\n",
    "\n",
    "        # Get the low resolution agent images\n",
    "        inputs_agent = inputs.clone()\n",
    "        inputs_agent = torch.nn.functional.interpolate(inputs_agent, (lr_size, lr_size))\n",
    "        probs = F.sigmoid(agent.forward(inputs_agent))\n",
    "\n",
    "        # Sample the test-time policy\n",
    "        policy = probs.data.clone()\n",
    "        policy[policy<0.5] = 0.0\n",
    "        policy[policy>=0.5] = 1.0\n",
    "        # Get the masked high-res image and perform inference\n",
    "        inputs = utils.agent_chosen_input(inputs, policy, mappings, patch_size)\n",
    "        preds = vit_b_16(inputs)\n",
    "        patch_use = policy.sum(1).float() / policy.size(1)\n",
    "        _, pred_idx = preds.max(1)\n",
    "        match = (pred_idx==targets).data\n",
    "        patch_use_true_preds = patch_use[match]\n",
    "        average_patch_use+=patch_use_true_preds.sum()\n",
    "\n",
    "print(average_patch_use/len(valloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2918, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print((average_patch_use / (len(valloader)*128)) * 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
